{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOXvsoLMoAWocMnPiLJVu5/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shelyao/AI-quantitative-research/blob/master/Muti_Stock_Model_yx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoxOf2ivhgzb",
        "outputId": "ed3fb51e-1a9c-4c62-c7bf-938836d60cd7"
      },
      "source": [
        "!pip install jqdatasdk\n",
        "!pip install pyts\n",
        "from jqdatasdk import *\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pyts.image import GramianAngularField\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import random\n",
        "from collections import deque\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "# phone number / password for joinquant\n",
        "auth('18720012430','Luoluoblue1991')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jqdatasdk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/3e/58d3107349b9b268bb0d058d77363f0c5c91a85bffb44889ef073cc05359/jqdatasdk-1.8.8-py3-none-any.whl (151kB)\n",
            "\r\u001b[K     |██▏                             | 10kB 12.6MB/s eta 0:00:01\r\u001b[K     |████▎                           | 20kB 10.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 30kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 40kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 51kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 71kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 81kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 92kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 102kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 112kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 122kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 133kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 143kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from jqdatasdk) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.16.2 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk) (1.1.5)\n",
            "Collecting pymysql>=0.7.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/52/a115fe175028b058df353c5a3d5290b71514a83f67078a6482cff24d6137/PyMySQL-1.0.2-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.6MB/s \n",
            "\u001b[?25hCollecting thriftpy2>=0.3.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/d1/6b041449bd04b953294f3a070fc96bd8ce23ff81e96cc4c2920f7d555fe0/thriftpy2-0.4.14.tar.gz (361kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 17.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jqdatasdk) (2.23.0)\n",
            "Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk) (1.3.23)\n",
            "Requirement already satisfied: msgpack>=0.4.7 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk) (1.0.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.16.2->jqdatasdk) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.16.2->jqdatasdk) (2.8.1)\n",
            "Collecting ply<4.0,>=3.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/58/35da89ee790598a0700ea49b2a66594140f44dec458c07e8e3d4979137fc/ply-3.11-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->jqdatasdk) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jqdatasdk) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jqdatasdk) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jqdatasdk) (1.24.3)\n",
            "Building wheels for collected packages: thriftpy2\n",
            "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thriftpy2: filename=thriftpy2-0.4.14-cp37-cp37m-linux_x86_64.whl size=940263 sha256=44a4e4e791d7b0f3b8005035a391e86b481477e6a45eaf826d57b397718aa84f\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/c6/6b/c94a9a90153934a39a26ed4d94254d0e347b706f989b526c8b\n",
            "Successfully built thriftpy2\n",
            "Installing collected packages: pymysql, ply, thriftpy2, jqdatasdk\n",
            "Successfully installed jqdatasdk-1.8.8 ply-3.11 pymysql-1.0.2 thriftpy2-0.4.14\n",
            "Collecting pyts\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/2b/1a62c0d32b40ee85daa8f6a6160828537b3d846c9fe93253b38846c6ec1f/pyts-0.11.0-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.48.0 in /usr/local/lib/python3.7/dist-packages (from pyts) (0.51.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from pyts) (0.22.2.post1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts) (53.0.0)\n",
            "Installing collected packages: pyts\n",
            "Successfully installed pyts-0.11.0\n",
            "提示：当前环境 pandas 版本高于 0.25，get_price 与 get_fundamentals_continuously 接口 panel 参数将固定为 False\n",
            "注意：0.25 以上版本 pandas 不支持 panel，如使用该数据结构和相关函数请注意修改\n",
            "auth success \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EPlv2MAhsNC"
      },
      "source": [
        "def get_data(security, start_date, end_date):\n",
        "  #security = '000002.XSHE'\n",
        "  # get data\n",
        "  df_daily = get_price(security, start_date = start_date, end_date= end_date, frequency='daily')\n",
        "  df_daily.head()\n",
        "  df_hour = get_price(security, start_date = start_date, end_date= end_date, frequency='60m')\n",
        "  df_hour.head()\n",
        "  trading_hour = list(df_hour.index)\n",
        "  trading_day = list(df_daily.index)\n",
        "\n",
        "  # save necessary data\n",
        "  data = []\n",
        "  for index in range(30, len(trading_day)-2):\n",
        "    tmp = {}\n",
        "    tmp['time'] = trading_day[index].date()\n",
        "    end_index = trading_day.index(trading_day[index]) + 1\n",
        "    start_index = end_index - 10\n",
        "    tmp['day_close'] = list(df_daily[start_index:end_index]['close'])\n",
        "    tmp['day_high'] = list(df_daily[start_index:end_index]['high'])\n",
        "    tmp['day_open'] = list(df_daily[start_index:end_index]['open'])\n",
        "    tmp['day_low'] = list(df_daily[start_index:end_index]['low'])\n",
        "    tmp['day_volume'] = list(df_daily[start_index:end_index]['volume'])\n",
        "    tmp['reward'] = float(df_daily[end_index:end_index+1]['open']) - float(df_daily[end_index-1:end_index]['open'])\n",
        "    end_index = trading_hour.index(trading_day[index+1].date())\n",
        "    start_index = end_index - 10\n",
        "    tmp['hour_close'] = list(df_hour[start_index:end_index]['close'])\n",
        "    tmp['hour_high'] = list(df_hour[start_index:end_index]['high'])\n",
        "    tmp['hour_open'] = list(df_hour[start_index:end_index]['open'])\n",
        "    tmp['hour_low'] = list(df_hour[start_index:end_index]['low'])\n",
        "    tmp['hour_volume'] = list(df_hour[start_index:end_index]['volume'])\n",
        "    data.append(tmp)\n",
        "\n",
        "  # transfer list data into image data\n",
        "  image_data = []\n",
        "  for index in range(len(data)):\n",
        "    sample_input = data[index]\n",
        "    transformer = GramianAngularField()\n",
        "    sample_day_close = np.array(sample_input['day_close']).reshape(1,10)\n",
        "    sample_day_high = np.array(sample_input['day_high']).reshape(1,10)\n",
        "    sample_day_open = np.array(sample_input['day_open']).reshape(1,10)\n",
        "    sample_day_low = np.array(sample_input['day_low']).reshape(1,10)\n",
        "    sample_day_volume = np.array(sample_input['day_volume']).reshape(1,10)\n",
        "    sample_hour_close = np.array(sample_input['hour_close']).reshape(1,10)\n",
        "    sample_hour_high = np.array(sample_input['hour_high']).reshape(1,10)\n",
        "    sample_hour_open = np.array(sample_input['hour_open']).reshape(1,10)\n",
        "    sample_hour_low = np.array(sample_input['hour_low']).reshape(1,10)\n",
        "    sample_hour_volume = np.array(sample_input['hour_volume']).reshape(1,10)\n",
        "    new_sample_day_close = transformer.transform(sample_day_close)\n",
        "    new_sample_day_high = transformer.transform(sample_day_high)\n",
        "    new_sample_day_open = transformer.transform(sample_day_open)\n",
        "    new_sample_day_low = transformer.transform(sample_day_low)\n",
        "    new_sample_day_volume = transformer.transform(sample_day_volume)\n",
        "    new_sample_hour_close = transformer.transform(sample_hour_close)\n",
        "    new_sample_hour_high = transformer.transform(sample_hour_high)\n",
        "    new_sample_hour_open = transformer.transform(sample_hour_open)\n",
        "    new_sample_hour_low = transformer.transform(sample_hour_low)\n",
        "    new_sample_hour_volume = transformer.transform(sample_hour_volume)\n",
        "    sample_image = np.zeros((30,30))\n",
        "    for i in range(0,10):\n",
        "      for j in range(0,10):\n",
        "        sample_image[i][j] = new_sample_day_close[0][i][j]\n",
        "    for i in range(0,10):\n",
        "      for j in range(10,20):\n",
        "        sample_image[i][j] = new_sample_day_high[0][i][j-10]\n",
        "    for i in range(0,10):\n",
        "      for j in range(20,30):\n",
        "        sample_image[i][j] = new_sample_day_open[0][i][j-20]\n",
        "    for i in range(10,20):\n",
        "      for j in range(0,10):\n",
        "        sample_image[i][j] = new_sample_hour_close[0][i-10][j]\n",
        "    for i in range(10,20):\n",
        "      for j in range(10,20):\n",
        "        sample_image[i][j] = new_sample_hour_high[0][i-10][j-10]\n",
        "    for i in range(10,20):\n",
        "      for j in range(20,30):\n",
        "        sample_image[i][j] = new_sample_hour_open[0][i-10][j-20]\n",
        "    for i in range(20,30):\n",
        "      for j in range(0,10):\n",
        "        sample_image[i][j] = new_sample_day_low[0][i-20][j]\n",
        "    for i in range(20,30):\n",
        "      for j in range(10,20):\n",
        "        sample_image[i][j] = new_sample_hour_low[0][i-20][j-10]\n",
        "    for i in range(20,30):\n",
        "      for j in range(20,30):\n",
        "        sample_image[i][j] = new_sample_day_volume[0][i-20][j-20]\n",
        "    show_img = sample_image\n",
        "    sample_image = sample_image.reshape((30,30,1))\n",
        "    image_data.append(sample_image)\n",
        "  return data, image_data, df_daily\n",
        "\n",
        "def get_security_list(start, end, security_list = ['600519.XSHG', '601318.XSHG', '000858.XSHG', '600036.XSHG', '600276.XSHG', '000333.XSHE', '000651.XSHE', '600030.XSHG', '002475.XSHE']):\n",
        "  tmp_data_list = []\n",
        "  tmp_image_data_list = []\n",
        "  for security in security_list:\n",
        "    print(security)\n",
        "    data, image_data, df_daily = get_data(security, start, end)\n",
        "    tmp_data_list.append(data)\n",
        "    tmp_image_data_list.append(image_data)\n",
        "  length = len(tmp_data_list[0])\n",
        "  data = []\n",
        "  image_data = []\n",
        "  for i in range(length):\n",
        "    tmp_data = []\n",
        "    for j in range(len(tmp_data_list)):\n",
        "      tmp_data.append(tmp_data_list[j][i])\n",
        "    data.append(tmp_data)\n",
        "\n",
        "    tmp_image_data = [[[] for _ in range(30)] for _ in range(30) ]\n",
        "    for x in range(30):\n",
        "      for y in range(30):\n",
        "        for j in range(9):\n",
        "          tmp_image_data[x][y].append(tmp_image_data_list[j][i][x][y][0])\n",
        "    \n",
        "    image_data.append(tmp_image_data)\n",
        "  return data, image_data, df_daily"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B2krUvvh9Ak"
      },
      "source": [
        "# simulate environment\n",
        "class Env:\n",
        "  def __init__(self, data, image_data):\n",
        "    self.data = data\n",
        "    self.image_data = image_data\n",
        "    self.index = 0\n",
        "    self.length = len(data) - 1\n",
        "    self.done = False\n",
        "    self.actions = self.generate_action()\n",
        "\n",
        "  def current_state(self):\n",
        "    return [self.index, self.data[self.index], self.image_data[self.index]]\n",
        "\n",
        "  def step(self, action):\n",
        "    if self.done:\n",
        "      return 0, True\n",
        "    \n",
        "    self.index += 1\n",
        "    reward = 0\n",
        "    # change reward here\n",
        "    for i in range(9):\n",
        "      tmp = self.actions[action][i]\n",
        "      tmp = tmp / self.data[self.index][i]['day_open'][-1]\n",
        "      tmp = tmp * self.data[self.index][i]['reward']\n",
        "      reward += tmp\n",
        "    #\n",
        "    if self.index == self.length - 1:\n",
        "      self.done = True\n",
        "    return self.image_data[self.index], reward, self.done\n",
        "\n",
        "  def reset(self):\n",
        "    self.index = 0\n",
        "    self.done = False\n",
        "    return self.image_data[self.index]\n",
        "    # return state\n",
        "  def generate_action(self, n=9, delta=0.1):\n",
        "    # n : number of stocks\n",
        "    # delta : resolution\n",
        "    ans = []\n",
        "    tmp = []\n",
        "    def get_next(tmp, left):\n",
        "      if len(tmp) == n:\n",
        "        ans.append(tmp)\n",
        "        return\n",
        "      \n",
        "      for i in range(left+1):\n",
        "        get_next(tmp+[i], left-i)\n",
        "    get_next(tmp, n)\n",
        "    return ans\n",
        "  "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a2IAvgdh4lP"
      },
      "source": [
        "class DqnAgent():\n",
        "    def __init__(self):\n",
        "        self.q_net = self._build_dqn_model()\n",
        "        self.target_q_net = self._build_dqn_model()\n",
        "        self.action_space = 48620\n",
        "    \n",
        "    @staticmethod\n",
        "    def _build_dqn_model():\n",
        "        q_net = models.Sequential()\n",
        "        q_net.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(30, 30, 9)))\n",
        "        q_net.add(layers.MaxPooling2D((2, 2)))\n",
        "        q_net.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "        #q_net.add(layers.MaxPooling2D((2, 2)))\n",
        "        q_net.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "        q_net.add(layers.Flatten())\n",
        "        q_net.add(layers.Dense(64, activation='relu'))\n",
        "        q_net.add(layers.Dense(48620))\n",
        "        q_net.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
        "                      loss='mse')\n",
        "        #q_net.summary()\n",
        "        return q_net\n",
        "\n",
        "    def random_policy(self, state):\n",
        "        return np.random.randint(0, self.action_space)\n",
        "\n",
        "    def collect_policy(self, state):\n",
        "        if np.random.random() < 0.05:\n",
        "            return self.random_policy(state)\n",
        "        return self.policy(state)\n",
        "\n",
        "    def policy(self, state):\n",
        "        state_input = tf.convert_to_tensor([state], dtype=tf.float32)\n",
        "        action_q = self.q_net(state_input)\n",
        "        action = np.argmax(action_q.numpy()[0], axis=0)\n",
        "        return action\n",
        "\n",
        "    def update_target_network(self):\n",
        "        self.target_q_net.set_weights(self.q_net.get_weights())\n",
        "\n",
        "    def train(self, batch):\n",
        "        state_batch, next_state_batch, action_batch, reward_batch, done_batch = batch\n",
        "        state_batch = tf.convert_to_tensor(state_batch, dtype=tf.float32)\n",
        "        current_q = self.q_net(state_batch).numpy()\n",
        "        target_q = np.copy(current_q)\n",
        "        next_state_batch = tf.convert_to_tensor(next_state_batch, dtype=tf.float32)\n",
        "        next_q = self.target_q_net(next_state_batch).numpy()\n",
        "        max_next_q = np.amax(next_q, axis=1)\n",
        "        for i in range(state_batch.shape[0]):\n",
        "            target_q_val = reward_batch[i]\n",
        "            if not done_batch[i]:\n",
        "                target_q_val += 0.95 * max_next_q[i]\n",
        "            target_q[i][action_batch[i]] = target_q_val\n",
        "        training_history = self.q_net.fit(x=state_batch, y=target_q, verbose=0)\n",
        "        loss = training_history.history['loss']\n",
        "        return loss\n",
        "\n",
        "class ReplayBuffer:\n",
        "  def __init__(self):\n",
        "    self.experiences = deque()\n",
        "    self.max_length = 1000000\n",
        "\n",
        "  def store(self, state, next_state, reward, action, done):\n",
        "    if len(self.experiences) >= self.max_length:\n",
        "      self.experiences.popleft()\n",
        "    self.experiences.append((state, next_state, reward, action, done))\n",
        "\n",
        "  def sample(self):\n",
        "    batch_size = min(128, len(self.experiences))\n",
        "    sampled_batch = random.sample(self.experiences, batch_size)\n",
        "    state_batch, next_state_batch, action_batch, reward_batch, done_batch = [], [], [], [], []\n",
        "    for gameplay_experience in sampled_batch:\n",
        "      state_batch.append(gameplay_experience[0])\n",
        "      next_state_batch.append(gameplay_experience[1])\n",
        "      reward_batch.append(gameplay_experience[2])\n",
        "      action_batch.append(gameplay_experience[3])\n",
        "      done_batch.append(gameplay_experience[4])\n",
        "    return state_batch, next_state_batch, action_batch, reward_batch, done_batch"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBlVhX7hh8AR"
      },
      "source": [
        "def evaluate_training_result(env, agent, buffer):\n",
        "    total_reward = 0.0\n",
        "    episodes_to_play = 1\n",
        "    for i in range(episodes_to_play):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        episode_reward = 0.0\n",
        "        while not done:\n",
        "            action = agent.policy(state)\n",
        "            next_state, reward, done = env.step(action)\n",
        "            buffer.store(state, next_state, reward, action, done)\n",
        "            episode_reward += reward\n",
        "            state = next_state\n",
        "        total_reward += episode_reward\n",
        "    average_reward = total_reward / episodes_to_play\n",
        "    return average_reward\n",
        "\n",
        "\n",
        "def collect_experiences(env, agent, buffer):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = agent.collect_policy(state)\n",
        "        next_state, reward, done = env.step(action)\n",
        "        buffer.store(state, next_state, reward, action, done)\n",
        "        state = next_state\n",
        "\n",
        "# change max_episodes here\n",
        "def train_model(data, image_data, max_episodes=6000):\n",
        "    env = Env(data, image_data)\n",
        "    agent = DqnAgent()\n",
        "    buffer = ReplayBuffer()\n",
        "    for _ in range(1):\n",
        "        collect_experiences(env, agent, buffer)\n",
        "    for episode_cnt in range(max_episodes):\n",
        "        #collect_experiences(env, agent, buffer)\n",
        "        gameplay_experience_batch = buffer.sample()\n",
        "        loss = agent.train(gameplay_experience_batch)\n",
        "        avg_reward = evaluate_training_result(env, agent, buffer)\n",
        "        print('Episode {0}/{1} and so far the performance is {2} and '\n",
        "              'loss is {3}'.format(episode_cnt, max_episodes,\n",
        "                                   avg_reward, loss[0]))\n",
        "        if episode_cnt % 20 == 0:\n",
        "            agent.update_target_network()\n",
        "    print('No bug lol!!!')\n",
        "    return agent"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQWsRptCijTn",
        "outputId": "bed93530-2d63-4fac-9b6c-a75f17622357"
      },
      "source": [
        "#train_data, train_image_data, _ = get_security_list(start = '2018-01-01', end = '2019-12-31')\n",
        "agent = train_model(data = train_data, image_data = train_image_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 0/6000 and so far the performance is 3.4519824631611304 and loss is 4.946508624925627e-07\n",
            "Episode 1/6000 and so far the performance is 3.565421800177013 and loss is 1.0119306352862623e-06\n",
            "Episode 2/6000 and so far the performance is 4.343030138498592 and loss is 6.758875201740011e-07\n",
            "Episode 3/6000 and so far the performance is 4.248344108250244 and loss is 6.052532057765347e-07\n",
            "Episode 4/6000 and so far the performance is 5.111488100209211 and loss is 9.6268240667996e-07\n",
            "Episode 5/6000 and so far the performance is 5.77566699952514 and loss is 7.551181511189498e-07\n",
            "Episode 6/6000 and so far the performance is 4.794207821078376 and loss is 8.276518315142312e-07\n",
            "Episode 7/6000 and so far the performance is 4.528092122073695 and loss is 5.73002807868761e-07\n",
            "Episode 8/6000 and so far the performance is 4.397767040462041 and loss is 6.289658358582528e-07\n",
            "Episode 9/6000 and so far the performance is 3.5044920196665656 and loss is 3.932960908059613e-07\n",
            "Episode 10/6000 and so far the performance is 3.906080488517886 and loss is 5.197347263674601e-07\n",
            "Episode 11/6000 and so far the performance is 4.200880710444577 and loss is 6.676908128611103e-07\n",
            "Episode 12/6000 and so far the performance is 3.8521277891597276 and loss is 5.957479629614681e-07\n",
            "Episode 13/6000 and so far the performance is 4.089874488476938 and loss is 5.713729933631839e-07\n",
            "Episode 14/6000 and so far the performance is 3.3497888011725983 and loss is 6.999421202635858e-07\n",
            "Episode 15/6000 and so far the performance is 4.439935216939954 and loss is 9.513535133010009e-07\n",
            "Episode 16/6000 and so far the performance is 4.241561919640056 and loss is 1.245954535988858e-06\n",
            "Episode 17/6000 and so far the performance is 4.0521613563744525 and loss is 1.6407470866397489e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp_SmVfRjLBU"
      },
      "source": [
        "def evalModelPerformance(image_data, figure = True):\n",
        "  test_action = []\n",
        "  for i in range(len(image_data)-1):\n",
        "    state1 = image_data[i]\n",
        "    a = agent.collect_policy(state1)\n",
        "    test_action.append(actions[a])\n",
        "\n",
        "  before = []\n",
        "  after = []\n",
        "  bah_money = [100000 for _ in range(9)]\n",
        "  bah_shares = [0 for _ in range(9)]\n",
        "  long_money = [100000 for _ in range(9)]\n",
        "  long_shares = [0 for _ in range(9)]\n",
        "  extra_money = 0\n",
        "  #total_long_money = 400000\n",
        "  for i in range(len(test_action)):\n",
        "    for j in range(9):\n",
        "      if long_shares[j] != 0:\n",
        "        long_money[j] = long_shares[j] * open_price[j][i+1]\n",
        "        long_shares[j] = 0\n",
        "      if bah_shares[j] != 0:\n",
        "        bah_money[j] = bah_shares[j] * open_price[j][i+1]\n",
        "        bah_shares[j] = 0\n",
        "    before.append(sum(bah_money))\n",
        "    after.append(sum(long_money)+extra_money)\n",
        "    # print(long_money)\n",
        "    # print(test_action[i])\n",
        "    total_long_money = sum(long_money) + extra_money\n",
        "    for j in range(9):\n",
        "      if i > 0:\n",
        "        loss_pct = (open_price[j][i] - open_price[j][i-1]) / open_price[j][i-1]\n",
        "        if loss_pct < -0.03:\n",
        "          long_shares[j] = 0\n",
        "          # print('stop loss')\n",
        "          # print(loss_pct)\n",
        "          # print(i,j)\n",
        "          # print(test_action[i][j])\n",
        "        else:\n",
        "          long_shares[j] = total_long_money * test_action[i][j] / 9 / open_price[j][i+1]\n",
        "      else:\n",
        "        long_shares[j] = total_long_money * test_action[i][j] / 9 / open_price[j][i+1]\n",
        "      long_money[j] = long_shares[j] * open_price[j][i+1]\n",
        "      bah_shares[j] = bah_money[j]/open_price[j][i+1]\n",
        "    extra_money = after[-1] - sum(long_money)\n",
        "    if figure:\n",
        "      plt.plot(after,label='after')\n",
        "      plt.plot(bah,label='bah')\n",
        "      plt.plot(after_without_stoploss,label=\"after_without\")\n",
        "      plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXH8GYnfzG22"
      },
      "source": [
        "evalModelPerformance(train_image_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjslz-2ozVHN"
      },
      "source": [
        "test_data, test_image_data = get_security_list(start = '2020-01-01', end = '2020-12-31')\n",
        "evalModelPerformance(test_image_data)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}